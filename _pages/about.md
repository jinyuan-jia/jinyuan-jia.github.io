---
permalink: /
title: "About me"
excerpt: "About me"
author_profile: true
redirect_from: 
  - /about/
  - /about.html
---


Welcome to Jinyuan Jia's homepage!

I am an Assistant Professor of Information Sciences and Technology at the Pennsylvania State University. My current research focuses on 1) identifying security/safety issues of LLM-centered AI systems, and 2) enhancing the trustworthiness (e.g., transparency) of those systems.

Previously, I was a postdoc at the University
of Illinois Urbana-Champaign under the supervision of [Prof. Bo Li](https://aisecure.github.io/). I received a B.E. from the [University of Science and Technology of China (USTC)](https://ustc.edu.cn) in 2016, a M.E. from [Iowa State University](https://iastate.edu) in 2019, and a Ph.D. from the Electrical and Computer Engineering Department at [Duke University](https://duke.edu) under the supervision of [Prof. Neil Zhenqiang Gong](https://people.duke.edu/~zg70/) in 2022.

## Research Interests

- Provably secure/robust machine learning system
- Security/safety of LLM-centric AI system 
- Security and privacy vulnerabilities of other machine learning system (federated learning, foundation model ecosystem, graph neural network, etc.)

## Selected Publications [(Full List)](https://jinyuan-jia.github.io/publications/)

* Wei Zou\*, Runpeng Geng\*, Binghui Wang, and **Jinyuan Jia**. "[PoisonedRAG: Knowledge Poisoning Attacks to Retrieval-Augmented Generation of Large Language Models](https://arxiv.org/pdf/2402.07867)". In *USENIX Security Symposium*, 2025. *Equal contribution

* Yupei Liu, Yuqi Jia, Runpeng Geng, **Jinyuan Jia**, and Neil Zhenqiang Gong. "[Formalizing and Benchmarking Prompt Injection Attacks and Defenses](https://arxiv.org/abs/2310.12815)". In *USENIX Security Symposium*, 2024.

* Yanting Wang, Wei Zou, and **Jinyuan Jia**. "[FCert: Provably Robust Few-Shot Classification in the Era of Foundation Model](https://arxiv.org/pdf/2404.08631)". In *IEEE Symposium on Security and Privacy (IEEE S&P)*, 2024.

* Zaishuo Xia\*, Han Yang\*, Binghui Wang, and **Jinyuan Jia**. "[GNNCert: Deterministic Certification of Graph Neural Networks against Adversarial Perturbations](https://openreview.net/forum?id=IGzaH538fz)". In *International Conference on Learning Representations (ICLR)*, 2024. \*Equal contribution

* Hengzhi Pei, **Jinyuan Jia**, Wenbo Guo, Bo Li, and Dawn Song. "[TextGuard: Provable Defense against Backdoor Attacks on Text
Classification](https://arxiv.org/pdf/2311.11225.pdf)". In *Network and Distributed System Security Symposium (NDSS)*, 2024.

* **Jinyuan Jia\***, Yupei Liu\*, Yuepeng Hu, and Neil Zhenqiang Gong. "[PORE: Provably Robust Recommender Systems against Data Poisoning Attacks](https://arxiv.org/pdf/2303.14601.pdf)". In *USENIX Security Symposium*, 2023. *Equal contribution

* **Jinyuan Jia\***, Yupei Liu\*, and Neil Zhenqiang Gong.  "[BadEncoder: Backdoor Attacks to Pre-trained Encoders in Self-Supervised Learning](https://arxiv.org/pdf/2108.00352.pdf)". In *IEEE Symposium on Security and Privacy (IEEE S&P)*, 2022. \*Equal contribution 

* **Jinyuan Jia**, Xiaoyu Cao, and Neil Zhenqiang Gong. "[Intrinsic Certified Robustness of Bagging against Data Poisoning Attacks](https://arxiv.org/pdf/2008.04495)". In *AAAI Conference on Artificial Intelligence (AAAI)*, 2021. 


* Minghong Fang\*, Xiaoyu Cao\*, **Jinyuan Jia**, and Neil Zhenqiang Gong. "[Local Model Poisoning Attacks to Byzantine-Robust Federated Learning](https://www.usenix.org/system/files/sec20summer_fang_prepub.pdf)". In *USENIX Security Symposium*, 2020. \*Equal contribution

* **Jinyuan Jia**, Ahmed Salem, Michael Backes, Yang Zhang, and Neil Zhenqiang Gong. "[MemGuard: Defending against Black-Box Membership Inference Attacks via Adversarial Examples](https://arxiv.org/pdf/1909.10594)". In *ACM Conference on Computer and Communications Security (CCS)*, 2019. 

* **Jinyuan Jia** and Neil Zhenqiang Gong. "[AttriGuard: A Practical Defense Against Attribute Inference Attacks via Adversarial Machine Learning](https://www.usenix.org/system/files/conference/usenixsecurity18/sec18-jia.pdf)". In *USENIX Security Symposium*, 2018. 

## Current Ph.D. Students

- Runpeng Geng (08/2024 - Now)
- Yanting Wang (08/2023 - Now)
- Wei Zou (08/2023 - Now)

