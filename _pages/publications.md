---
layout: archive
title: "Publications"
permalink: /publications/
author_profile: true
---

## 2025

* Yupei Liu, Yuqi Jia, **Jinyuan Jia**, and Neil Zhenqiang Gong. "[Evaluating LLM-based Personal Information Extraction and Countermeasures](https://arxiv.org/abs/2408.07291)". In *USENIX Security Symposium*, 2025. [<span style="color:red">code</span>](https://doi.org/10.5281/zenodo.14737200)


* Wenjie Qu, Wengrui Zheng, Tianyang Tao, Dong Yin, Yanze Jiang, Zhihua Tian, Wei Zou, **Jinyuan Jia**, and Jiaheng Zhang. "[Provably Robust Multi-bit Watermarking for AI-generated Text](https://arxiv.org/abs/2401.16820)". In *USENIX Security Symposium*, 2025. [<span style="color:red">code</span>](https://github.com/randomizedtree/segment-watermark)

* Wei Zou\*, Runpeng Geng\*, Binghui Wang, and **Jinyuan Jia**. "[PoisonedRAG: Knowledge Corruption Attacks to Retrieval-Augmented Generation of Large Language Models](https://arxiv.org/pdf/2402.07867)". In *USENIX Security Symposium*, 2025. *Equal contribution [<span style="color:red">code</span>](https://github.com/sleeepeer/PoisonedRAG)

* Yupei Liu, Yuqi Jia, **Jinyuan Jia**, Dawn Song, and Neil Zhenqiang Gong. "[DataSentinel: A Game-Theoretic Detection of Prompt Injection Attacks](https://arxiv.org/abs/2504.11358)". In *IEEE Symposium on Security and Privacy (IEEE S\&P)*, 2025. [<span style="color:red">code</span>](https://github.com/liu00222/Open-Prompt-Injection) \
<span style="color:red">Distinguished Paper Award</span>

* Lingyu Du, Yupei Liu, **Jinyuan Jia**, and Guohao Lan. "[SecureGaze: Defending Gaze Estimation Against Backdoor Attacks
](https://dl.acm.org/doi/pdf/10.1145/3715014.3722071)". In *ACM Conference on Embedded Networked Sensor Systems (SenSys)*, 2025. [<span style="color:red">code</span>](https://github.com/LingyuDu/SecureGaze)


## 2024


* Zhangchen Xu, Fengqing Jiang, Luyao Niu, **Jinyuan Jia**, Bo Li, and Radha Poovendran. "[ACE: A Model Poisoning Attack on Contribution Evaluation Methods
in Federated Learning](https://arxiv.org/pdf/2405.20975)". In *USENIX Security Symposium*, 2024.

* Yupei Liu, Yuqi Jia, Runpeng Geng, **Jinyuan Jia**, and Neil Zhenqiang Gong. "[Formalizing and Benchmarking Prompt Injection Attacks and Defenses](https://arxiv.org/abs/2310.12815)". In *USENIX Security Symposium*, 2024. [<span style="color:red">code</span>](https://github.com/liu00222/Open-Prompt-Injection)

* Yuxin Yang, Qiang Li, **Jinyuan Jia**, Yuan Hong, and Binghui Wang. "[Distributed Backdoor Attacks on Federated Graph Learning and Certified Defenses](https://arxiv.org/pdf/2407.08935)". In *ACM Conference on Computer and Communications Security (CCS)*, 2024. [<span style="color:red">code</span>](https://github.com/Yuxin104/Opt-GDBA) \
<span style="color:red">Distinguished Paper Award</span>

* Zhengyuan Jiang, Moyang Guo, Yuepeng Hu, **Jinyuan Jia**, and Neil Zhenqiang Gong. "[Certifiably Robust Image Watermark](https://arxiv.org/pdf/2407.04086)". In *European Conference on Computer Vision (ECCV)*, 2024. [<span style="color:red">code</span>](https://github.com/uw-nsl/SafeDecoding)

* Lingyu Du, **Jinyuan Jia**, Xucong Zhang, and Guohao Lan. "[PrivateGaze: Preserving User Privacy in Black-box Mobile Gaze Tracking Services](https://dl.acm.org/doi/pdf/10.1145/3678595)". In *ACM on Interactive, Mobile, Wearable and Ubiquitous Technologies (UbiComp)*, 2024. [<span style="color:red">code</span>](https://github.com/LingyuDu/PrivateGaze)

* Zhangchen Xu, Fengqing Jiang, Luyao Niu, **Jinyuan Jia**, Bill Yuchen Lin, and Radha Poovendran. "[SafeDecoding: Defending against Jailbreak Attacks via Safety-Aware Decoding](https://arxiv.org/abs/2402.08983)". In *Annual Meeting of the Association for Computational Linguistics (ACL)*, 2024. [<span style="color:red">code</span>](https://github.com/uw-nsl/SafeDecoding)

* Hangfan Zhang, Zhimeng Guo, Huaisheng Zhu, Bochuan Cao, Lu Lin, **Jinyuan Jia**, Jinghui Chen, and Dinghao Wu. "[Jailbreak Open-Sourced Large Language Models via Enforced Decoding
](https://arxiv.org/abs/2310.01581)". In *Annual Meeting of the Association for Computational Linguistics (ACL)*, 2024. [<span style="color:red">code</span>](https://github.com/hfzhang31/EnDec)

* Jiate Li, Meng Pang, Yun Dong, **Jinyuan Jia**, and Binghui Wang. "[Graph Neural Network Explanations are Fragile](https://arxiv.org/pdf/2406.03193)". In *International Conference on Machine Learning (ICML)*, 2024. [<span style="color:red">code</span>](https://github.com/JetRichardLee/Attack-XGNN)

* Zhuowen Yuan, Wenbo Guo, **Jinyuan Jia**, Bo Li, and Dawn Song. "[SHINE: Shielding Backdoors in Deep Reinforcement Learning](https://openreview.net/pdf?id=nMWxLnSBGW)". In *International Conference on Machine Learning (ICML)*, 2024.
  
* Jinghuai Zhang, Hongbin Liu, **Jinyuan Jia**, and Neil Zhenqiang Gong. "[Data Poisoning based Backdoor Attacks to Contrastive Learning](https://arxiv.org/pdf/2211.08229)". In *IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)*, 2024. [<span style="color:red">code</span>](https://github.com/jzhang538/CorruptEncoder)

* Yuan Xiao, Shiqing Ma, Juan Zhai, Chunrong Fang, **Jinyuan Jia**, and Zhenyu Chen. "[Towards General Robustness Verification of MaxPool-based Convolutional Neural Networks via Tightening Linear Approximation](https://openaccess.thecvf.com/content/CVPR2024/papers/Xiao_Towards_General_Robustness_Verification_of_MaxPool-based_Convolutional_Neural_Networks_via_CVPR_2024_paper.pdf)". In *IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)*, 2024.

* Yanting Wang, Hongye Fu, Wei Zou, and **Jinyuan Jia**. "[MMCert: Provable Defense against Adversarial Attacks to Multi-modal Models](https://arxiv.org/pdf/2403.19080)". In *IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)*, 2024. [<span style="color:red">code</span>](https://github.com/WYT8506/MultimodalCertification)

* Yanting Wang, Wei Zou, and **Jinyuan Jia**. "[FCert: Provably Robust Few-Shot Classification in the Era of Foundation Model](https://arxiv.org/pdf/2404.08631)". In *IEEE Symposium on Security and Privacy (IEEE S&P)*, 2024.

* Zaishuo Xia\*, Han Yang\*, Binghui Wang, and **Jinyuan Jia**. "[GNNCert: Deterministic Certification of Graph Neural Networks against Adversarial Perturbations](https://openreview.net/forum?id=IGzaH538fz)". In *International Conference on Learning Representations (ICLR)*, 2024. \*Equal contribution  [<span style="color:red">code</span>](https://github.com/XiaFire/GNNCERT) \
<span style="color:red">Oral Presentation</span>


* Hengzhi Pei, **Jinyuan Jia**, Wenbo Guo, Bo Li, and Dawn Song. "[TextGuard: Provable Defense against Backdoor Attacks on Text
Classification](https://arxiv.org/pdf/2311.11225.pdf)". In *Network and Distributed System Security Symposium (NDSS)*, 2024. [<span style="color:red">code</span>](https://github.com/AI-secure/TextGuard)


## 2023

* Bochuan Cao, Changjiang Li, Ting Wang, **Jinyuan Jia**, Bo Li, and Jinghui Chen. "[IMPRESS: Evaluating the Resilience of Imperceptible Perturbations Against Unauthorized Data Usage in Diffusion-Based Generative AI](https://arxiv.org/pdf/2310.19248.pdf)". In *Conference on Neural Information Processing Systems (NeurIPS)*, 2023. 

* Hangfan Zhang, **Jinyuan Jia**, Jinghui Chen, Lu Lin, and Dinghao Wu. "[A3FL: Adversarially Adaptive Backdoor Attacks to Federated Learning](https://openreview.net/pdf?id=S6ajVZy6FA)". In *Conference on Neural Information Processing Systems (NeurIPS)*, 2023. 

* **Jinyuan Jia\***, Zhuowen Yuan\*, Dinuka Sahabandu, Luyao Niu, Arezoo Rajabi, Bhaskar Ramasubramanian, Bo Li, and Radha Poovendran. "[FedGame: A Game-Theoretic Defense against Backdoor Attacks in Federated Learning](https://openreview.net/pdf?id=nX0zYBGEka)". In *Conference on Neural Information Processing Systems (NeurIPS)*, 2023. \*Equal contribution 

* Hanting Ye, Guohao Lan, **Jinyuan Jia**, and Qing Wang. "[Screen Perturbation: Adversarial Attack and Defense on Under-Screen Camera](https://dl.acm.org/doi/pdf/10.1145/3570361.3613278)". In *International Conference on Mobile Computing and Networking (MobiCom)*, 2023.

* **Jinyuan Jia\***, Yupei Liu\*, Yuepeng Hu, and Neil Zhenqiang Gong. "[PORE: Provably Robust Recommender Systems against Data Poisoning Attacks](https://arxiv.org/pdf/2303.14601.pdf)". In *USENIX Security Symposium*, 2023. *Equal contribution

* Hangfan Zhang, Jinghui Chen, Lu Lin, **Jinyuan Jia**, and Dinghao Wu. "[Graph Contrastive Backdoor Attacks](https://openreview.net/pdf?id=BfVkbfJGW4)". In *International Conference on Machine Learning (ICML)*, 2023.

* Jinghuai Zhang, **Jinyuan Jia**, Hongbin Liu, and Neil Zhenqiang Gong. "[PointCert: Point Cloud Classification with Deterministic Certified Robustness Guarantees](https://arxiv.org/pdf/2303.01959.pdf)". In *IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)*, 2023.

* Xiaoyu Cao, **Jinyuan Jia**, Zaixi Zhang, and Neil Zhenqiang Gong. "[FedRecover: Recovering from Poisoning Attacks in Federated Learning using Historical Information](https://www.computer.org/csdl/proceedings-article/sp/2023/933600a326/1He7Y3q8FMY)". In *IEEE Symposium on Security and Privacy (IEEE S&P)*, 2023.

* Wenjie Qu, **Jinyuan Jia**, and Neil Zhenqiang Gong. "[REaaS: Enabling Adversarially Robust Downstream Classifiers via Robust Encoder as a Service
](https://arxiv.org/pdf/2301.02905v1.pdf
)". In *Network and Distributed System Security Symposium (NDSS)*, 2023.

## 2022

*  Xiaoyu Cao, Zaixi Zhang, **Jinyuan Jia**, and Neil Zhenqiang Gong. "[FLCert: Provably Secure Federated Learning against Poisoning Attacks](https://arxiv.org/pdf/2210.00584.pdf)". *IEEE Transactions on Information Forensics and Security (TIFS)*, 2022. 

* **Jinyuan Jia\***, Wenjie Qu\*, and Neil Zhenqiang Gong. "[MultiGuard: Provably Robust Multi-label Classification against Adversarial Examples](https://arxiv.org/pdf/2210.01111.pdf)". In *Conference on Neural Information Processing Systems (NeurIPS)*, 2022. \*Equal contribution [<span style="color:red">code</span>](https://github.com/quwenjie/MultiGuard)

* Yupei Liu, **Jinyuan Jia**, Hongbin Liu, and Neil Zhenqiang Gong. "[StolenEncoder: Stealing Pre-trained Encoders in Self-supervised Learning](https://arxiv.org/pdf/2201.05889.pdf)". In *ACM Conference on Computer and Communications Security (CCS)*, 2022.

* Zaixi Zhang, Xiaoyu Cao, **Jinayuan Jia**, and Neil Zhenqiang Gong. "[FLDetector: Defending Federated Learning Against Model Poisoning Attacks via Detecting Malicious Clients](https://arxiv.org/pdf/2207.09209.pdf)". In *ACM SIGKDD Conference on Knowledge Discovery and Data Mining (KDD)*, 2022. [<span style="color:red">code</span>](https://github.com/zaixizhang/FLDetector)

* Hongbin Liu, **Jinyuan Jia**, and Neil Zhenqiang Gong. "[PoisonedEncoder: Poisoning the Unlabeled Pre-training Data in Contrastive Learning](https://arxiv.org/pdf/2205.06401.pdf)". In *USENIX Security Symposium*, 2022.

* Yongji Wu, Xiaoyu Cao, **Jinyuan Jia**, and Neil Zhenqiang Gong. "[Poisoning Attacks to Local Differential Privacy Protocols for Key-Value Data](https://arxiv.org/pdf/2111.11534.pdf)". In *USENIX Security Symposium*, 2022.

* **Jinyuan Jia\***, Yupei Liu\*, and Neil Zhenqiang Gong.  "[BadEncoder: Backdoor Attacks to Pre-trained Encoders in Self-Supervised Learning](https://arxiv.org/pdf/2108.00352.pdf)". In *IEEE Symposium on Security and Privacy (IEEE S&P)*, 2022. \*Equal contribution [<span style="color:red">code</span>](https://github.com/jjy1994/BadEncoder)
* **Jinyuan Jia**, Binghui Wang, Xiaoyu Cao, Hongbin Liu, and Neil Zhenqiang Gong. "[Almost Tight L0-norm Certified Robustness of Top-k Predictions against Adversarial Perturbations](https://arxiv.org/abs/2011.07633)". In *International Conference on Learning Representations (ICLR)*, 2022.

* **Jinyuan Jia**, Yupei Liu, Xiaoyu Cao, and Neil Zhenqiang Gong. "[Certified Robustness of Nearest Neighbors against Data Poisoning and Backdoor Attacks](https://arxiv.org/pdf/2012.03765.pdf)". In *AAAI Conference on Artificial Intelligence (AAAI)*, 2022.


## 2021

* Hongbin Liu\*, **Jinyuan Jia\***, Wenjie Qu, and Neil Zhenqiang Gong.  "[EncoderMI: Membership Inference against Pre-trained Encoders in Contrastive Learning](https://arxiv.org/pdf/2108.11023.pdf)". In *ACM Conference on Computer and Communications Security (CCS)*, 2021. *Equal contribution

* Binghui Wang, **Jinyuan Jia**, Xiaoyu Cao, and Neil Zhenqiang Gong.  "[Certified Robustness of Graph Neural Networks against Adversarial Structural Perturbation](https://arxiv.org/pdf/2008.10715.pdf)". In *ACM SIGKDD Conference on Knowledge Discovery and Data Mining (KDD)*, 2021.

* Hongbin Liu, **Jinyuan Jia**, and Neil Zhenqiang Gong. "[On the Intrinsic Differential Privacy of Bagging](https://arxiv.org/pdf/2008.09845.pdf)". In *International Joint Conference on Artificial Intelligence (IJCAI)*, 2021.

* Xiaoyu Cao, **Jinyuan Jia**, and Neil Zhenqiang Gong. "[Data Poisoning Attacks to Local Differential Privacy Protocols](https://arxiv.org/pdf/1911.02046.pdf)". In *USENIX Security Symposium*, 2021.

* Xinlei He, **Jinyuan Jia**, Michael Backes, Neil Zhenqiang Gong, and Yang Zhang. "[Stealing Links from Graph Neural Networks](https://arxiv.org/pdf/2005.02131.pdf)". In *USENIX Security Symposium*, 2021. [<span style="color:red">code</span>](https://github.com/xinleihe/link_stealing_attack)

* Hongbin Liu\*, **Jinyuan Jia\***, and Neil Zhenqiang Gong. "[PointGuard: Provably Robust 3D Point Cloud Classification](https://arxiv.org/pdf/2103.03046.pdf)". In *IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)*, 2021. \*Equal contribution

* Zaixi Zhang\*, **Jinyuan Jia\***, Binghui Wang, and Neil Zhenqiang Gong. "[Backdoor Attacks to Graph Neural Networks](https://arxiv.org/pdf/2006.11165)". In *ACM Symposium on Access Control Models and Technologies (SACMAT)*, 2021. \*Equal contribution [<span style="color:red">code</span>](https://github.com/zaixizhang/graphbackdoor)

* Xiaoyu Cao, **Jinyuan Jia**, and Neil Zhenqiang Gong. "[IPGuard: Protecting Intellectual Property of Deep Neural Networks via Fingerprinting the Classification Boundary](https://arxiv.org/pdf/1910.12903.pdf)". In *ACM ASIA Conference on Computer and Communications Security (ASIACCS)*, 2021.

* **Jinyuan Jia**, Binghui Wang, and Neil Zhenqiang Gong. "[Robust and Verifiable Information Embedding Attacks to Deep Neural Networks via Error-Correcting Codes](https://arxiv.org/pdf/2010.13751.pdf)". In *ACM ASIA Conference on Computer and Communications Security (ASIACCS)*, 2021.

* Xiaoyu Cao, **Jinyuan Jia**, and Neil Zhenqiang Gong. "[Provably Secure Federated Learning against Malicious Clients](https://arxiv.org/pdf/2102.01854)". In *AAAI Conference on Artificial Intelligence (AAAI)*, 2021.

* **Jinyuan Jia**, Xiaoyu Cao, and Neil Zhenqiang Gong. "[Intrinsic Certified Robustness of Bagging against Data Poisoning Attacks](https://arxiv.org/pdf/2008.04495)". In *AAAI Conference on Artificial Intelligence (AAAI)*, 2021. [<span style="color:red">code</span>](https://github.com/jjy1994/BaggingCertifyDataPoisoning)

* Binghui Wang, **Jinyuan Jia**, and Neil Zhenqiang Gong. "[Semi-Supervised Node Classification on Graphs: Markov Random Fields vs. Graph Neural Networks](https://arxiv.org/pdf/2012.13085)". In *AAAI Conference on Artificial Intelligence (AAAI)*, 2021.


## 2020


* Zaixi Zhang, **Jinyuan Jia**, Binghui Wang, and Neil Zhenqiang Gong. "[Backdoor Attacks to Graph Neural Networks](http://securedata.lol/camera_ready/13.pdf)". *NeurIPS 2020 Workshop on Dataset Curation and Security*, 2020.

* Binghui Wang, Xiaoyu Cao, **Jinyuan Jia**, and Neil Zhenqiang Gong. "[On Certifying Robustness against Backdoor Attacks via Randomized Smoothing](https://arxiv.org/pdf/2002.11750)". *CVPR 2020 Workshop on Adversarial Machine Learning in Computer Vision*, 2020. \
<span style="color:red">DeepMind Best Extended Abstract Award</span>

* **Jinyuan Jia\***, Binghui Wang\*, Xiaoyu Cao, and Neil Zhenqiang Gong. "[Certified Robustness of Community Detection against Adversarial Structural Perturbation via Randomized Smoothing](https://arxiv.org/pdf/2002.03421)". In *The Web Conference (WWW)*, 2020. \*Equal contribution

* **Jinyuan Jia**, Xiaoyu Cao, Binghui Wang, and Neil Zhenqiang Gong. "[Certified Robustness for Top-k Predictions against Adversarial Perturbations via Randomized Smoothing](https://arxiv.org/pdf/1912.09899)". In *International Conference on Learning Representations (ICLR)*, 2020. [<span style="color:red">code</span>](https://github.com/jjy1994/Certify_Topk)

* Minghong Fang\*, Xiaoyu Cao\*, **Jinyuan Jia**, and Neil Zhenqiang Gong. "[Local Model Poisoning Attacks to Byzantine-Robust Federated Learning](https://www.usenix.org/system/files/sec20summer_fang_prepub.pdf)". In *USENIX Security Symposium*, 2020. \*Equal contribution 

* **Jinyuan Jia** and Neil Zhenqiang Gong. "[Defending against Machine Learning based Inference Attacks via Adversarial Examples: Opportunities and Challenges](https://arxiv.org/pdf/1909.08526)". *Adaptive Autonomous Secure Cyber Systems. Springer, Cham*, 2020.


## 2019

* **Jinyuan Jia**, Ahmed Salem, Michael Backes, Yang Zhang, and Neil Zhenqiang Gong. "[MemGuard: Defending against Black-Box Membership Inference Attacks via Adversarial Examples](https://arxiv.org/pdf/1909.10594)". In *ACM Conference on Computer and Communications Security (CCS)*, 2019. [<span style="color:red">code</span>](https://github.com/jjy1994/MemGuard)

* **Jinyuan Jia** and Neil Zhenqiang Gong. "[Calibrate: Frequency Estimation and Heavy Hitter Identification with Local Differential Privacy via Incorporating Prior Knowledge](https://arxiv.org/pdf/1812.02055)". In *IEEE International Conference on Computer Communications (INFOCOM)*, 2019. 

* Binghui Wang, **Jinyuan Jia**, and Neil Zhenqiang Gong. "[Graph-based Security and Privacy Analytics via Collective Classification with Joint Weight Learning and Propagation](https://arxiv.org/pdf/1812.01661)". In *ISOC Network and Distributed System Security Symposium (NDSS)*, 2019. \
<span style="color:red">Distinguished Paper Award Honorable Mention</span>

* Binghui Wang, **Jinyuan Jia**, Le Zhang, and Neil Zhenqiang Gong. "[Structure-based Sybil Detection in Social Networks via Local Rule-based Propagation](https://arxiv.org/pdf/1803.04321)". *IEEE Transactions on Network Science and Engineering (TNSE)*, 6(3), 2019.

## 2018


* **Jinyuan Jia** and Neil Zhenqiang Gong. "[AttriGuard: A Practical Defense Against Attribute Inference Attacks via Adversarial Machine Learning](https://www.usenix.org/system/files/conference/usenixsecurity18/sec18-jia.pdf)". In *USENIX Security Symposium*, 2018. [<span style="color:red">code</span>](https://github.com/jjy1994/AttriGuard) \
<span style="color:red">Featured by [WIRED](https://www.wired.com/story/adversarial-examples-machine-learning-privacy-social-media/), [Boing Boing](https://boingboing.net/2019/10/02/mockingbird-and-attriguard.html)</span>


## 2017

* **Jinyuan Jia**, Binghui Wang, and Neil Zhenqiang Gong. ''[Random Walk based Fake Account Detection in Online Social Networks](https://ieeexplore.ieee.org/abstract/document/8023129)". In *IEEE/IFIP International Conference on Dependable Systems and Networks (DSN)*, 2017.

* **Jinyuan Jia**, Binghui Wang, Le Zhang, and Neil Zhenqiang Gong. ''[AttriInfer: Inferring User Attributes in Online Social Networks Using Markov Random Fields](https://dl.acm.org/doi/abs/10.1145/3038912.3052695)". In *International Conference on World Wide Web (WWW)*, 2017.
